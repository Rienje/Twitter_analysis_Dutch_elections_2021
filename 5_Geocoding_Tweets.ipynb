{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d16c185",
   "metadata": {},
   "source": [
    "## Geocoding Tweets\n",
    "This script showcases how we geocoded (e.g. added coordinates) to tweets containing a placename in the Netherlands. For this, we made use of cbsodata and Nominatim from geopy, which uses the OSM database for geocoding strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa76137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import cbsodata\n",
    "\n",
    "# Load cleaned locations from previous script\n",
    "df = pd.read_csv('cleaned_geo_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087e3363",
   "metadata": {},
   "source": [
    "#### Final check for geocoding\n",
    "In order to be sure that the geolocator will pick up the names from our tweets, we run the tweets through a loop that compares them with an official list of residences (e.g. villages, cities, hamlets, etc.) from [CBS](https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=84992NED&_theme=238), so that we are sure the geolocater won't crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1223e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata from cbsodata\n",
    "metadata = pd.DataFrame(cbsodata.get_meta('84992NED', 'DataProperties'))\n",
    "\n",
    "# Save placenames as dataframe\n",
    "places = pd.DataFrame(cbsodata.get_data('84992NED', select = 'Woonplaatsen'))\n",
    "\n",
    "# Read the places csv file \n",
    "#places = pd.read_csv('Woonplaatsen_in_Nederland.csv',sep = ';')\n",
    "\n",
    "# Make sure the names are in lower case to match our names \n",
    "places['Woonplaatsen'] = places['Woonplaatsen'].str.lower()\n",
    "\n",
    "# Create an empty list for the place names to be added to\n",
    "legit_locs = []\n",
    "# Create the loop\n",
    "for i in df['location']:\n",
    "    for j in places['Woonplaatsen']:\n",
    "        if i == j:\n",
    "            legit_locs.append(i)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# Create dataframe of location and count\n",
    "fnl_df = pd.DataFrame(legit_locs)\n",
    "\n",
    "# Name the column for clarity\n",
    "fnl_df.columns =['Location']\n",
    "\n",
    "# Add a count column\n",
    "fnl_df['count'] = fnl_df.groupby('Location')['Location'].transform('count')\n",
    "\n",
    "# Remove the duplicates\n",
    "fnl_df.drop_duplicates(subset=['Location'], keep = 'first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398b2bc",
   "metadata": {},
   "source": [
    "#### Geocoding\n",
    "Now, it's time for the actual geocoding. Be aware that this line takes around 10 minutes to locate all the placenames. The code was inspired by [this](https://medium.com/analytics-vidhya/exploring-twitter-data-using-python-part-iii-analyzing-the-data-e883aa340dff) tutorial. Alternatively, the 'tweets_with_location' file is also provided in the next notebook, so the user doesn't have to run the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a082ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inititiate user\n",
    "geolocator = Nominatim(user_agent='twitter-analysis')\n",
    "# note that user_agent is a random name\n",
    "\n",
    "# Convert locations to a list\n",
    "fnl_locs = list(fnl_df.Location)\n",
    "\n",
    "# This line takes about 10 minutes to run!\n",
    "geolocated = list(map(lambda x: [x,geolocator.geocode(x)[1] if geolocator.geocode(x) else None],fnl_locs))\n",
    "\n",
    "# Check the result\n",
    "geolocated.head(5)\n",
    "\n",
    "# Transform to lat and long\n",
    "geolocated = pd.DataFrame(geolocated)\n",
    "geolocated.columns = ['locat','latlong']\n",
    "geolocated['lat'] = geolocated.latlong.apply(lambda x: x[0])\n",
    "geolocated['lon'] = geolocated.latlong.apply(lambda x: x[1])\n",
    "geolocated.drop('latlong',axis=1, inplace=True)\n",
    "\n",
    "# Procedure to merge the sentiment and spatial analysis\n",
    "tweets_with_location = df.join(geolocated.set_index('locat'), on = 'location')\n",
    "\n",
    "# Export to csv for the final notebook!\n",
    "tweets_with_location.to_csv('tweets_with_location.csv', header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
