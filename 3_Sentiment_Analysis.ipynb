{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4dd33d8",
   "metadata": {},
   "source": [
    "## Sentiment analysis\n",
    "This script uses the cleaned tweets and tags them with a sentiment polarity score (ranging from -1 (negative) to 1 (positive)). After comparing different methods for sentiment analysis, it was found that the [Google Natural Language sentiment analyzer](https://cloud.google.com/natural-language/docs) provided the most accurate result (based on an inspection of the results). Therefore, only this method will be documented here, while the other methods will be covered in Rienje's portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76179d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deep_translator import GoogleTranslator\n",
    "from google.cloud import language_v1\n",
    "\n",
    "# Load cleaned tweets from previous script\n",
    "df = pd.read_csv('cleaned_sentiment_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99755c7",
   "metadata": {},
   "source": [
    "#### Translating tweets\n",
    "Unfortunately, Dutch sentiment analysis is currently not possible due to a [bug](https://issuetracker.google.com/issues/180714982) in the Google Natural Language tool. Therefore, we need to translate the tweets to English prior to analysis. This reduces the accuracy of the sentiment analysis, although the Google API still yields better scores than Dutch sentiment analyses (like [pattern.nl](https://github.com/clips/pattern/wiki/pattern-nl) or analyses based on [classified Dutch tweets](https://github.com/cltl-students/Eva_Zegelaar_Emotion_Classification_Dutch_Political_Tweets)). We translate the tweet using the [deep-translator](https://pypi.org/project/deep-translator/) wrapper for the Google translate API, which actually allows unlimited translating for free.\n",
    "The code below takes several hours to run, so we suggest the reader uses the provided data in the next notebook, instead of running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b948a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a list\n",
    "translatedList = []\n",
    "\n",
    "# This loop takes a long time (several hours!) to run for all 18k tweets\n",
    "for tweet in split['text_for_translation']:\n",
    "    translation = GoogleTranslator(source='nl', dest='en').translate(tweet)\n",
    "    translatedList.append(translation)\n",
    "    \n",
    "# Stitch translation to df\n",
    "df['translation'] = translatedList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7511392f",
   "metadata": {},
   "source": [
    "#### The sentiment analysis\n",
    "Provided below is the code that sends the tweets to the Google Cloud and returns a sentiment score. This code will probably yield an error if the user does not have a Google Cloud service account. Also, the costs of the sentiment analysis are roughly 1 dollar per 1000 tweets, so running the block below is not recommended. Instead, the tweets with the tagged sentiments will be loaded in the next notebook. The code is an adaptation from [Stackoverflow](https://stackoverflow.com/questions/61319178/how-can-i-send-a-batch-of-strings-to-the-google-cloud-natural-language-api).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9f8ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Google natural language sentiment analysis\n",
    "# Costs are roughly 1 dollar per 1000 tweets\n",
    "# Running the google cloud takes a long time, ~4 hours for 18 000 tweets\n",
    "\n",
    "# Check instantiation of client\n",
    "client = language_v1.LanguageServiceClient.from_service_account_json(\"D:/Users/Rienje/Documents/MGI Wageningen/SmartEnvironmentDataScience/Project/Python/googleNL/sentiment-309511-2a1624b4263f.json\")\n",
    "\n",
    "# Create a function that retrieves sentiment score from Google NL API\n",
    "def comment_analysis(comment):\n",
    "    \n",
    "    # Re-instantiate client\n",
    "    client = language_v1.LanguageServiceClient.from_service_account_json(\"D:/Users/Rienje/Documents/MGI Wageningen/SmartEnvironmentDataScience/Project/Python/googleNL/sentiment-309511-2a1624b4263f.json\")\n",
    "    # Set parameters for analysis\n",
    "    document = {\"content\":comment,\n",
    "                \"type_\":language_v1.Document.Type.PLAIN_TEXT,\n",
    "                \"language\":\"en\"}\n",
    "    # Sentiment analysis\n",
    "    annotations = client.analyze_sentiment(document=document)\n",
    "    # Append only the sentiment score of the tweet\n",
    "    total_score = annotations.document_sentiment.score\n",
    "    return total_score\n",
    "\n",
    "# Initiate list\n",
    "GoogleCloudList = []\n",
    "\n",
    "# Retrieve sentiment score for al tweets\n",
    "for tweet in df['translation']:\n",
    "    googlesentiment = comment_analysis(tweet)\n",
    "    GoogleCloudList.append(googlesentiment)\n",
    "\n",
    "# Add to df and save as csv\n",
    "df['google_scores'] = GoogleCloudList\n",
    "df.to_csv('final_sentiment_tweets.csv', header=True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd2da7",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "There are many modules for sentiment analysis available for Python, although finding an *accurate* sentiment analyzer for Dutch is much more difficult. During the project, an estimation was made of which of four (machine learning, Google Cloud, Pattern and NLTK Vader) was the most 'accurate' for our project. In the end, as described above, the choice was made for the Google Cloud analyzer. This API also has some downsides however.\n",
    "\n",
    "First, like many of Google's services, it is very black box-y. The user has little insight on how certain tweets are tagged, in contrast with academic classifiers (like [Pattern](https://github.com/clips/pattern) and, to a lesser extent, [NLTK](https://www.nltk.org/api/nltk.sentiment.html). In addition, the texts had to be translated, which inevitably leads to a loss of context, sentence structure and thus, sentiment. The database was too large (or time too limited) to check the translations.\n",
    "Therefore, the results of the sentiment analysis should be taken with a grain of salt. In addition to reasons described above, tweet sentiment analysis is quite tricky in itself, as the sentences are short and often informal or sarcastic (especially when concerning complex political tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018608f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
